\section{Discussion}

The results presented above highlight both the strengths and limitations of incorporating cross-lingual morphological consistency into tokenization. Our method succeeds in reshaping the embedding space in linguistically meaningful ways, aligning equivalent plural markers across English and Turkish and improving boundary recovery for morphologically rich languages such as German. These gains support our central claim: tokenization benefits from grounding subword units in grammatical structure rather than relying solely on frequency statistics.

However, the results also reveal important asymmetries. Improvements are most pronounced in languages with productive morphology, where affixal structure provides strong distributional signals. In contrast, analytic languages such as English offer fewer opportunities for morphological generalization, and their simpler word-formation patterns reduce the impact of cross-lingual consistency. This suggests that morphology-aware tokenization may be most beneficial for languages with rich inflectional paradigms or agglutinative structures.

Another limitation concerns coverage of the \textsc{CROSS\_EQUIV} dictionary. While our manually curated equivalence classes capture high-level morpheme categories (e.g., plurality), they remain sparse relative to the full diversity of morphological processes across languages. Expanding these equivalence mappings, especially for low-resource languages with limited annotated data, could yield more robust cross-lingual generalization. This is particularly relevant for languages with complex case systems, noun class markers, or polysynthetic morphology, where character-level distributions alone provide insufficient structure.

A promising direction for future work is leveraging unsupervised or weakly supervised morphology discovery methods to automatically propose frequently occurring morphemes and map them across languages. Techniques such as context distribution modeling, contrastive morpheme mining, or geographical/contextual clustering of affixes may help identify productive morphological patterns absent from high-resource languages. Incorporating these automatically discovered morphemes into the \textsc{CROSS\_EQUIV} dictionary could improve coverage and adapt the tokenizer to linguistic phenomena not captured by current hand-curated mappings.

Finally, extending this approach to smaller or endangered languages presents a particularly impactful opportunity. Many of these languages exhibit rich morphology but lack large training corpora. A morphology-aware tokenizer that transfers structural insights from high-resource languages may enable more efficient learning under severe data scarcity. Such extensions would move tokenization closer to a more typologically universal representation layer, improving multilingual modeling in both low-resource and geographically diverse contexts.
